{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TW4hI-5Fw_FE"
   },
   "source": [
    "<a href=\"https://kaggle.com/code/ritvik1909/siamese-network\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "OAAUsjMxw6ma"
   },
   "source": [
    "# Siamese Network\n",
    "\n",
    "A Siamese neural network (sometimes called a twin neural network) is an artificial neural network that uses the same weights while working in tandem on two different input vectors to compute comparable output vectors.\n",
    "\n",
    "Often one of the output vectors is precomputed, thus forming a baseline against which the other output vector is compared. This is similar to comparing fingerprints but can be described more technically as a distance function for locality-sensitive hashing.\n",
    "\n",
    "It is possible to make a kind of structure that is functional similar to a siamese network, but implements a slightly different function. This is typically used for comparing similar instances in different type sets.\n",
    "\n",
    "Uses of similarity measures where a twin network might be used are such things as recognizing handwritten checks, automatic detection of faces in camera images, and matching queries with indexed documents. The perhaps most well-known application of twin networks are face recognition, where known images of people are precomputed and compared to an image from a turnstile or similar. It is not obvious at first, but there are two slightly different problems. One is recognizing a person among a large number of other persons, that is the facial recognition problem.\n",
    "\n",
    "Source: [Wikipedia](https://en.wikipedia.org/wiki/Siamese_neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-04-01T14:46:09.010522Z",
     "iopub.status.busy": "2022-04-01T14:46:09.010194Z",
     "iopub.status.idle": "2022-04-01T14:46:14.040252Z",
     "shell.execute_reply": "2022-04-01T14:46:14.039438Z",
     "shell.execute_reply.started": "2022-04-01T14:46:09.010490Z"
    },
    "executionInfo": {
     "elapsed": 2293,
     "status": "ok",
     "timestamp": 1648877908309,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "ErVZSzL8w6me"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers, utils, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prw5qfNew6mf"
   },
   "source": [
    "Lets start off by creating our dataset. Our input data will be consisting of pairs of images, and output will be either 1 or 0 indicating if the pair are similar or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T14:46:14.042352Z",
     "iopub.status.busy": "2022-04-01T14:46:14.042027Z",
     "iopub.status.idle": "2022-04-01T14:46:14.052334Z",
     "shell.execute_reply": "2022-04-01T14:46:14.051406Z",
     "shell.execute_reply.started": "2022-04-01T14:46:14.042324Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1648877908311,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "y_h0cSuxw6mg"
   },
   "outputs": [],
   "source": [
    "def make_pairs(images, labels, seed=19):\n",
    "    np.random.seed(seed)\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "    \n",
    "    numClasses = len(np.unique(labels))\n",
    "    idx = [np.where(labels == i)[0] for i in range(numClasses)]\n",
    "\n",
    "    for idxA in range(len(images)):\n",
    "        currentImage = images[idxA]\n",
    "        label = labels[idxA]\n",
    "        \n",
    "        idxB = np.random.choice(idx[label])\n",
    "        posImage = images[idxB]\n",
    "        \n",
    "        pairImages.append([currentImage, posImage])\n",
    "        pairLabels.append([1])\n",
    "\n",
    "        negIdx = np.where(labels != label)[0]\n",
    "        negImage = images[np.random.choice(negIdx)]\n",
    "        \n",
    "        pairImages.append([currentImage, negImage])\n",
    "        pairLabels.append([0])\n",
    "    \n",
    "    return (np.array(pairImages), np.array(pairLabels))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vrjuoSDw6mg"
   },
   "source": [
    "We will be working with `MNIST` dataset in our notebook which comes along with the tensorflow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-01T14:46:14.054287Z",
     "iopub.status.busy": "2022-04-01T14:46:14.053699Z",
     "iopub.status.idle": "2022-04-01T14:46:23.809877Z",
     "shell.execute_reply": "2022-04-01T14:46:23.809059Z",
     "shell.execute_reply.started": "2022-04-01T14:46:14.054245Z"
    },
    "executionInfo": {
     "elapsed": 24049,
     "status": "ok",
     "timestamp": 1648877932348,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "PAJIVYrgw6mh",
    "outputId": "fe95d301-0dfd-4ca3-c98d-25ef010cb2c9"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\n",
    "trainX = 1 - (trainX / 255.0)\n",
    "testX  = 1 - (testX / 255.0)\n",
    "\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "\n",
    "(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
    "(pairTest, labelTest) = make_pairs(testX, testY)\n",
    "\n",
    "print(f'\\nTrain Data Shape: {pairTrain.shape}')\n",
    "print(f'Test  Data Shape: {pairTest.shape}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBy-yF9Iw6mi"
   },
   "source": [
    "Lets visualize the mnist images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "execution": {
     "iopub.execute_input": "2022-04-01T14:46:23.812279Z",
     "iopub.status.busy": "2022-04-01T14:46:23.811691Z",
     "iopub.status.idle": "2022-04-01T14:46:24.381571Z",
     "shell.execute_reply": "2022-04-01T14:46:24.380711Z",
     "shell.execute_reply.started": "2022-04-01T14:46:23.812231Z"
    },
    "executionInfo": {
     "elapsed": 1075,
     "status": "ok",
     "timestamp": 1648877933417,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "PJthfWA6w6mi",
    "outputId": "31765a33-a803-403e-85ce-30ef61c20b1f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 6, figsize=(20, 6))\n",
    "random.seed(19)\n",
    "idx = random.choices(range(len(trainX)), k=12)\n",
    "for i in range(12):\n",
    "    ax[i//6][i%6].imshow(np.squeeze(trainX[idx[i]]), cmap='gray')\n",
    "    ax[i//6][i%6].set_title(f'Label: {trainY[idx[i]]}', fontsize=18)\n",
    "    ax[i//6][i%6].set_axis_off()\n",
    "fig.suptitle('MNIST Images', fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHP_-Wj7w6mj"
   },
   "source": [
    "Here is a sample of our prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "execution": {
     "iopub.execute_input": "2022-04-01T14:46:24.384833Z",
     "iopub.status.busy": "2022-04-01T14:46:24.384487Z",
     "iopub.status.idle": "2022-04-01T14:46:24.791767Z",
     "shell.execute_reply": "2022-04-01T14:46:24.790799Z",
     "shell.execute_reply.started": "2022-04-01T14:46:24.384802Z"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1648877933419,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "pOmShTLXw6mj",
    "outputId": "e44261dc-6baa-4283-bc9f-25df3b8548fb"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 6, figsize=(20, 6))\n",
    "random.seed(19)\n",
    "idx = random.choices(range(len(pairTrain)), k=6)\n",
    "for i in range(0, 12, 2):\n",
    "    ax[i//6][i%6].imshow(np.squeeze(pairTrain[idx[i//2]][0]), cmap='gray')\n",
    "    ax[i//6][i%6+1].imshow(np.squeeze(pairTrain[idx[i//2]][1]), cmap='gray')\n",
    "    ax[i//6][i%6].set_title(f'Label: {labelTrain[idx[i//2]]}', fontsize=18)\n",
    "    ax[i//6][i%6].set_axis_off()\n",
    "    ax[i//6][i%6+1].set_axis_off()\n",
    "fig.suptitle('Input Pair Images', fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8N5_Ee4Aw6mk"
   },
   "source": [
    "Here we define some configurations for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T14:46:24.793672Z",
     "iopub.status.busy": "2022-04-01T14:46:24.793306Z",
     "iopub.status.idle": "2022-04-01T14:46:24.800983Z",
     "shell.execute_reply": "2022-04-01T14:46:24.798602Z",
     "shell.execute_reply.started": "2022-04-01T14:46:24.793642Z"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1648877933422,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "HftBev7Ew6mk"
   },
   "outputs": [],
   "source": [
    "class config():\n",
    "    IMG_SHAPE = (28, 28, 1)\n",
    "    EMBEDDING_DIM = 48\n",
    "    \n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_AMXzKow6mk"
   },
   "source": [
    "Here we define a function to calculate euclidean distance between two vectors. This will be used by our model to calculate the euclidean distance between the vectors of the image pairs (image vectors will be created by the feature extractor of our model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T14:46:24.803691Z",
     "iopub.status.busy": "2022-04-01T14:46:24.803047Z",
     "iopub.status.idle": "2022-04-01T14:46:24.812099Z",
     "shell.execute_reply": "2022-04-01T14:46:24.811006Z",
     "shell.execute_reply.started": "2022-04-01T14:46:24.803620Z"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1648877933424,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "wb9NwizXw6ml"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    (featsA, featsB) = vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW9hpE4_w6ml"
   },
   "source": [
    "With Siamese Network, the two most commonly used loss functions are:\n",
    "* contrastive loss\n",
    "* triplet loss\n",
    "\n",
    "We will be using contrastive loss in this notebook ie:\n",
    "\n",
    "```Contrastive loss = mean( (1-true_value) * square(prediction) + true_value * square( max(margin - prediction, 0)))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T14:46:24.814676Z",
     "iopub.status.busy": "2022-04-01T14:46:24.814000Z",
     "iopub.status.idle": "2022-04-01T14:46:24.824946Z",
     "shell.execute_reply": "2022-04-01T14:46:24.823903Z",
     "shell.execute_reply.started": "2022-04-01T14:46:24.814629Z"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1648877933426,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "ICXLZFp1w6ml"
   },
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtFBjwEyw6mm"
   },
   "source": [
    "Finally we define our model architecture\n",
    "\n",
    "* The model contains two input layers\n",
    "* A feature extractor through which both the images will be passed to generate feature vectors, the feature extractor typically consists of Convolutional and Pooling Layers\n",
    "* The feature vectors are passed through a custom layer to get euclidean distance between the vectors\n",
    "* The final layer consists of a single sigmoid unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T14:46:24.827411Z",
     "iopub.status.busy": "2022-04-01T14:46:24.826654Z",
     "iopub.status.idle": "2022-04-01T14:46:27.133936Z",
     "shell.execute_reply": "2022-04-01T14:46:27.133040Z",
     "shell.execute_reply.started": "2022-04-01T14:46:24.827365Z"
    },
    "executionInfo": {
     "elapsed": 1651,
     "status": "ok",
     "timestamp": 1648877935048,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "UFUpR9O5w6mm"
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(Model):\n",
    "    def __init__(self, inputShape, embeddingDim):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        imgA = layers.Input(shape=inputShape)\n",
    "        imgB = layers.Input(shape=inputShape)\n",
    "        featureExtractor = self.build_feature_extractor(inputShape, embeddingDim)\n",
    "        featsA = featureExtractor(imgA)\n",
    "        featsB = featureExtractor(imgB)\n",
    "        distance = layers.Lambda(euclidean_distance, name='euclidean_distance')([featsA, featsB])\n",
    "        outputs = layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "        self.model = Model(inputs=[imgA, imgB], outputs=outputs)        \n",
    "        \n",
    "    def build_feature_extractor(self, inputShape, embeddingDim=48):\n",
    "\n",
    "        model = Sequential([\n",
    "            layers.Input(inputShape),\n",
    "            layers.Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=2),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=2),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Conv2D(128, (1, 1), padding=\"same\", activation=\"relu\"),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(embeddingDim, activation='tanh')\n",
    "        ])\n",
    "\n",
    "        return model  \n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = SiameseNetwork(inputShape=config.IMG_SHAPE, embeddingDim=config.EMBEDDING_DIM)\n",
    "model.compile(loss=loss(margin=1), optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-04-01T14:46:27.677082Z",
     "iopub.status.busy": "2022-04-01T14:46:27.676707Z",
     "iopub.status.idle": "2022-04-01T14:56:20.212695Z",
     "shell.execute_reply": "2022-04-01T14:56:20.211833Z",
     "shell.execute_reply.started": "2022-04-01T14:46:27.677043Z"
    },
    "executionInfo": {
     "elapsed": 901615,
     "status": "ok",
     "timestamp": 1648878836651,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "6dC6hZFHw6mn",
    "outputId": "534125d2-e152-4032-e8a3-6f8056e7cb74",
    "tags": [
     "same_step_1"
    ]
   },
   "outputs": [],
   "source": [
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True, min_delta=1e-4)\n",
    "\n",
    "rlp = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, mode='min', verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    [pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n",
    "    validation_data=([pairTest[:, 0], pairTest[:, 1]], labelTest[:]),\n",
    "    batch_size=config.BATCH_SIZE, \n",
    "    epochs=config.EPOCHS,\n",
    "    callbacks=[es, rlp]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "execution": {
     "iopub.execute_input": "2022-04-01T14:56:20.214650Z",
     "iopub.status.busy": "2022-04-01T14:56:20.214291Z",
     "iopub.status.idle": "2022-04-01T14:56:21.973724Z",
     "shell.execute_reply": "2022-04-01T14:56:21.972847Z",
     "shell.execute_reply.started": "2022-04-01T14:56:20.214612Z"
    },
    "executionInfo": {
     "elapsed": 2998,
     "status": "ok",
     "timestamp": 1648878839616,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "yaoZMPSMw6mo",
    "outputId": "3cfa4e39-bfe0-4f8e-d96c-0cadfdcc471b"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 6, figsize=(20, 6))\n",
    "random.seed(19)\n",
    "idx = random.choices(range(len(pairTest)), k=6)\n",
    "preds = model.predict([pairTest[:, 0], pairTest[:, 1]])\n",
    "for i in range(0, 12, 2):\n",
    "    ax[i//6][i%6].imshow(np.squeeze(pairTest[idx[i//2]][0]), cmap='gray')\n",
    "    ax[i//6][i%6+1].imshow(np.squeeze(pairTest[idx[i//2]][1]), cmap='gray')\n",
    "    ax[i//6][i%6].set_title(f'Label: {labelTest[idx[i//2]]}', fontsize=18)\n",
    "    ax[i//6][i%6+1].set_title(f'Predicted: {np.round(preds[idx[i//2]], 2)}', fontsize=18)\n",
    "    ax[i//6][i%6].set_axis_off()\n",
    "    ax[i//6][i%6+1].set_axis_off()\n",
    "fig.suptitle('Test Pair Images', fontsize=24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "execution": {
     "iopub.execute_input": "2022-04-01T14:56:21.975349Z",
     "iopub.status.busy": "2022-04-01T14:56:21.974978Z",
     "iopub.status.idle": "2022-04-01T14:56:22.521939Z",
     "shell.execute_reply": "2022-04-01T14:56:22.521024Z",
     "shell.execute_reply.started": "2022-04-01T14:56:21.975318Z"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1648878839620,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "-YHSoBnXw6mo",
    "outputId": "47484ce9-dda1-4f64-e810-6832aff53b80"
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 8))\n",
    "df = pd.DataFrame(history.history)\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=ax[0])\n",
    "df[['loss', 'val_loss']].plot(ax=ax[1])\n",
    "ax[0].set_title('Model Accuracy', fontsize=12)\n",
    "ax[1].set_title('Model Loss', fontsize=12)\n",
    "fig.suptitle('Siamese Network: Learning Curve', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIYIkFCew6mo"
   },
   "source": [
    "# References\n",
    "[Fisher Discriminant Triplet and Contrastive Losses for Training Siamese Networks](https://arxiv.org/pdf/2004.04674v1.pdf)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "Siamese-Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
