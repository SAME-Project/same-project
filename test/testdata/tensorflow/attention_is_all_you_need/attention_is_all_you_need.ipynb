{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "-EKH_E-Z2bBp",
   "metadata": {
    "id": "-EKH_E-Z2bBp"
   },
   "source": [
    "<a href=\"https://www.kaggle.com/code/ritvik1909/neural-machine-translation-attention\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea58ad9",
   "metadata": {
    "id": "eea58ad9",
    "papermill": {
     "duration": 0.01953,
     "end_time": "2022-04-19T17:09:39.123240",
     "exception": false,
     "start_time": "2022-04-19T17:09:39.103710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "In this notebook we will implement a small transformer model for machine translation task. Our model would be able to translate human readable dates in any format to YYYY-MM-DD format.\n",
    "\n",
    "We will be using `faker` module to generate our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15b8f3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-19T17:09:39.165791Z",
     "iopub.status.busy": "2022-04-19T17:09:39.164311Z",
     "iopub.status.idle": "2022-04-19T17:09:51.020422Z",
     "shell.execute_reply": "2022-04-19T17:09:51.019834Z",
     "shell.execute_reply.started": "2022-04-19T16:26:16.961398Z"
    },
    "id": "4f15b8f3",
    "papermill": {
     "duration": 11.87833,
     "end_time": "2022-04-19T17:09:51.020579",
     "exception": false,
     "start_time": "2022-04-19T17:09:39.142249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72747262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:09:51.064603Z",
     "iopub.status.busy": "2022-04-19T17:09:51.063890Z",
     "iopub.status.idle": "2022-04-19T17:09:51.939467Z",
     "shell.execute_reply": "2022-04-19T17:09:51.939924Z",
     "shell.execute_reply.started": "2022-04-19T16:26:27.654284Z"
    },
    "id": "72747262",
    "papermill": {
     "duration": 0.899865,
     "end_time": "2022-04-19T17:09:51.940100",
     "exception": false,
     "start_time": "2022-04-19T17:09:51.040235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import re, random\n",
    "\n",
    "from faker import Faker\n",
    "from babel.dates import format_date\n",
    "\n",
    "pd.options.display.max_colwidth = None\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa08590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:09:51.986753Z",
     "iopub.status.busy": "2022-04-19T17:09:51.986001Z",
     "iopub.status.idle": "2022-04-19T17:09:56.373183Z",
     "shell.execute_reply": "2022-04-19T17:09:56.372645Z",
     "shell.execute_reply.started": "2022-04-19T16:26:28.610487Z"
    },
    "id": "aaa08590",
    "papermill": {
     "duration": 4.41297,
     "end_time": "2022-04-19T17:09:56.373332",
     "exception": false,
     "start_time": "2022-04-19T17:09:51.960362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import losses, callbacks, utils, models, Input\n",
    "from tensorflow.keras import layers as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3910c",
   "metadata": {
    "id": "5aa3910c",
    "papermill": {
     "duration": 0.019209,
     "end_time": "2022-04-19T17:09:56.411691",
     "exception": false,
     "start_time": "2022-04-19T17:09:56.392482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eeb03e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:09:56.454573Z",
     "iopub.status.busy": "2022-04-19T17:09:56.453776Z",
     "iopub.status.idle": "2022-04-19T17:09:56.456276Z",
     "shell.execute_reply": "2022-04-19T17:09:56.455821Z",
     "shell.execute_reply.started": "2022-04-19T16:26:33.512965Z"
    },
    "id": "86eeb03e",
    "papermill": {
     "duration": 0.026236,
     "end_time": "2022-04-19T17:09:56.456385",
     "exception": false,
     "start_time": "2022-04-19T17:09:56.430149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "class config():  \n",
    "    SAMPLE_SIZE = 10_00_000        \n",
    "    DATE_FORMATS = [\n",
    "        'short', 'medium', 'long', 'full',\n",
    "        'd MMM YYY', 'd MMMM YYY', 'dd/MM/YYY',\n",
    "        'EE d, MMM YYY', 'EEEE d, MMMM YYY', 'd of MMMM YYY',\n",
    "    ]\n",
    "    VALIDATION_SIZE = 0.1\n",
    "    BATCH_SIZE = 32\n",
    "    MAX_EPOCHS = 25\n",
    "    EMBED_DIM = 16\n",
    "    DENSE_DIM = 16\n",
    "    NUM_HEADS = 2\n",
    "    X_LEN = 30\n",
    "    Y_LEN = 14\n",
    "    NUM_ENCODER_TOKENS = 35\n",
    "    NUM_DECODER_TOKENS = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce1618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:09:56.497409Z",
     "iopub.status.busy": "2022-04-19T17:09:56.496869Z",
     "iopub.status.idle": "2022-04-19T17:09:56.550468Z",
     "shell.execute_reply": "2022-04-19T17:09:56.551032Z",
     "shell.execute_reply.started": "2022-04-19T16:26:33.526883Z"
    },
    "id": "b0ce1618",
    "outputId": "5aba41ad-61a3-4126-f7bc-ed7f5c6e3050",
    "papermill": {
     "duration": 0.076264,
     "end_time": "2022-04-19T17:09:56.551205",
     "exception": false,
     "start_time": "2022-04-19T17:09:56.474941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "faker = Faker()\n",
    "print('Sample dates for each format\\n')\n",
    "\n",
    "for fmt in set(config.DATE_FORMATS):\n",
    "    print(f'{fmt:20} =>  {format_date(faker.date_object(), format=fmt, locale=\"en\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60475f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:09:56.597660Z",
     "iopub.status.busy": "2022-04-19T17:09:56.596963Z",
     "iopub.status.idle": "2022-04-19T17:09:56.599245Z",
     "shell.execute_reply": "2022-04-19T17:09:56.599632Z",
     "shell.execute_reply.started": "2022-04-19T16:31:12.688221Z"
    },
    "id": "60475f85",
    "papermill": {
     "duration": 0.028292,
     "end_time": "2022-04-19T17:09:56.599753",
     "exception": false,
     "start_time": "2022-04-19T17:09:56.571461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a utility data cleaning function\n",
    "def clean_date(raw_date):\n",
    "    return raw_date.lower().replace(',', '')\n",
    "\n",
    "# this function will generate our data in a data frame\n",
    "def create_dataset(num_rows):\n",
    "    dataset = []\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        dt = faker.date_object()\n",
    "        for fmt in config.DATE_FORMATS:\n",
    "            try:\n",
    "                date = format_date(dt, format=fmt, locale='en')\n",
    "                human_readable = clean_date(date)\n",
    "                machine_readable = f\"@{dt.isoformat()}#\" # adding a start token '@' and end token '#'\n",
    "            except AttributeError as e:\n",
    "                date = None\n",
    "                human_readable = None\n",
    "                machine_readable = None\n",
    "            if human_readable is not None and machine_readable is not None:\n",
    "                dataset.append((human_readable, machine_readable))\n",
    " \n",
    "    return pd.DataFrame(dataset, columns=['human_readable', 'machine_readable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def5add",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "0ac32bd68ce545b59c43e0b6b6e5614d"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-04-19T17:09:56.642243Z",
     "iopub.status.busy": "2022-04-19T17:09:56.641504Z",
     "iopub.status.idle": "2022-04-19T17:14:50.497206Z",
     "shell.execute_reply": "2022-04-19T17:14:50.497826Z",
     "shell.execute_reply.started": "2022-04-19T16:31:13.00423Z"
    },
    "id": "6def5add",
    "outputId": "052d7e71-674c-4358-e65c-6e5a43e37b8f",
    "papermill": {
     "duration": 293.879505,
     "end_time": "2022-04-19T17:14:50.498045",
     "exception": false,
     "start_time": "2022-04-19T17:09:56.618540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate the dataset using the function defined above\n",
    "dataset = create_dataset(config.SAMPLE_SIZE)\n",
    "dataset  = dataset.drop_duplicates(subset=['human_readable']).sample(frac=1.0).reset_index(drop=True)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b6bea",
   "metadata": {
    "id": "a05b6bea",
    "papermill": {
     "duration": 0.021212,
     "end_time": "2022-04-19T17:14:50.541382",
     "exception": false,
     "start_time": "2022-04-19T17:14:50.520170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Define tokenizers for both the languages (human readable and machine readable dates)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ecad19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:14:50.640648Z",
     "iopub.status.busy": "2022-04-19T17:14:50.625463Z",
     "iopub.status.idle": "2022-04-19T17:14:52.799618Z",
     "shell.execute_reply": "2022-04-19T17:14:52.799144Z",
     "shell.execute_reply.started": "2022-04-19T16:36:12.52806Z"
    },
    "id": "c9ecad19",
    "outputId": "b948c056-5fef-4a5a-8516-af3dedfd6e0f",
    "papermill": {
     "duration": 2.237894,
     "end_time": "2022-04-19T17:14:52.799745",
     "exception": false,
     "start_time": "2022-04-19T17:14:50.561851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_tokenizer = Tokenizer(char_level=True)\n",
    "machine_tokenizer = Tokenizer(char_level=True)\n",
    "\n",
    "human_tokenizer.fit_on_texts(dataset['human_readable'].values)\n",
    "machine_tokenizer.fit_on_texts(dataset['machine_readable'].values)\n",
    "\n",
    "print(human_tokenizer.word_index)\n",
    "print(machine_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2446345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:14:52.847036Z",
     "iopub.status.busy": "2022-04-19T17:14:52.845469Z",
     "iopub.status.idle": "2022-04-19T17:14:52.847655Z",
     "shell.execute_reply": "2022-04-19T17:14:52.848052Z",
     "shell.execute_reply.started": "2022-04-19T16:36:14.614322Z"
    },
    "id": "a2446345",
    "papermill": {
     "duration": 0.02753,
     "end_time": "2022-04-19T17:14:52.848199",
     "exception": false,
     "start_time": "2022-04-19T17:14:52.820669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A utility function to clean and tokenize the text and then pad the sequence\n",
    "def preprocess_input(date, tokenizer, max_len):\n",
    "    seq = [i[0] for i in tokenizer.texts_to_sequences(date.lower().replace(',', ''))]\n",
    "    seq = pad_sequences([seq], padding='post', maxlen=max_len)[0]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b63eb",
   "metadata": {
    "id": "a82b63eb",
    "papermill": {
     "duration": 0.019917,
     "end_time": "2022-04-19T17:14:52.888246",
     "exception": false,
     "start_time": "2022-04-19T17:14:52.868329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Preprocessing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22eef4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:14:53.534066Z",
     "iopub.status.busy": "2022-04-19T17:14:53.044005Z",
     "iopub.status.idle": "2022-04-19T17:15:07.244362Z",
     "shell.execute_reply": "2022-04-19T17:15:07.244775Z",
     "shell.execute_reply.started": "2022-04-19T16:36:14.62205Z"
    },
    "id": "c22eef4b",
    "outputId": "92c02543-0b91-4219-d5b0-babf4e694409",
    "papermill": {
     "duration": 14.336399,
     "end_time": "2022-04-19T17:15:07.244929",
     "exception": false,
     "start_time": "2022-04-19T17:14:52.908530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X = np.array(list(map(lambda x: preprocess_input(x, human_tokenizer, config.X_LEN), dataset['human_readable'])))\n",
    "y = np.array(list(map(lambda x: preprocess_input(x, machine_tokenizer, config.Y_LEN), dataset['machine_readable'])))\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196d522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:15:07.290991Z",
     "iopub.status.busy": "2022-04-19T17:15:07.290336Z",
     "iopub.status.idle": "2022-04-19T17:15:07.444257Z",
     "shell.execute_reply": "2022-04-19T17:15:07.444685Z",
     "shell.execute_reply.started": "2022-04-19T16:36:28.203578Z"
    },
    "id": "b196d522",
    "papermill": {
     "duration": 0.178932,
     "end_time": "2022-04-19T17:15:07.444844",
     "exception": false,
     "start_time": "2022-04-19T17:15:07.265912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=config.VALIDATION_SIZE, random_state=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefc8974",
   "metadata": {
    "id": "aefc8974",
    "papermill": {
     "duration": 0.020711,
     "end_time": "2022-04-19T17:15:07.486561",
     "exception": false,
     "start_time": "2022-04-19T17:15:07.465850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A utility function to generate batches of data\n",
    "* encoder input data would be source language text\n",
    "* decoder input data would be target language text\n",
    "* decoder output data would be target language text shifted one time stamp forward (one hot encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae0af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:15:07.534541Z",
     "iopub.status.busy": "2022-04-19T17:15:07.533826Z",
     "iopub.status.idle": "2022-04-19T17:15:07.535804Z",
     "shell.execute_reply": "2022-04-19T17:15:07.536201Z",
     "shell.execute_reply.started": "2022-04-19T16:36:28.380373Z"
    },
    "id": "78ae0af8",
    "papermill": {
     "duration": 0.02915,
     "end_time": "2022-04-19T17:15:07.536332",
     "exception": false,
     "start_time": "2022-04-19T17:15:07.507182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size=config.BATCH_SIZE):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = X[j:j+batch_size]\n",
    "            decoder_input_data = y[j:j+batch_size]\n",
    "            output = y[j:j+batch_size]\n",
    "            decoder_output_data = np.zeros_like(output)\n",
    "            decoder_output_data[:,:-1] = output[:, 1:]\n",
    "            decoder_target_data = utils.to_categorical(decoder_output_data, num_classes=config.NUM_DECODER_TOKENS)\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ce58f",
   "metadata": {
    "id": "387ce58f",
    "papermill": {
     "duration": 0.020439,
     "end_time": "2022-04-19T17:15:07.577265",
     "exception": false,
     "start_time": "2022-04-19T17:15:07.556826",
     "status": "completed"
    },
    "tags": [
     "same_step_1"
    ]
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ca7f45",
   "metadata": {
    "id": "34ca7f45",
    "papermill": {
     "duration": 0.020627,
     "end_time": "2022-04-19T17:15:07.618444",
     "exception": false,
     "start_time": "2022-04-19T17:15:07.597817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's define the key components for our model\n",
    "* Positional Embedding Layer\n",
    "* Encoder Block\n",
    "* Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78e9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:15:07.681954Z",
     "iopub.status.busy": "2022-04-19T17:15:07.681151Z",
     "iopub.status.idle": "2022-04-19T17:15:07.683582Z",
     "shell.execute_reply": "2022-04-19T17:15:07.683101Z",
     "shell.execute_reply.started": "2022-04-19T16:41:41.27963Z"
    },
    "id": "0a78e9a7",
    "papermill": {
     "duration": 0.044262,
     "end_time": "2022-04-19T17:15:07.683694",
     "exception": false,
     "start_time": "2022-04-19T17:15:07.639432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(L.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = L.Embedding(input_dim, output_dim)\n",
    "        self.position_embeddings = L.Embedding(sequence_length, output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "class TransformerEncoder(L.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = L.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([L.Dense(dense_dim, activation='relu'), L.Dense(embed_dim)])\n",
    "        self.layernorm1 = L.LayerNormalization()\n",
    "        self.layernorm2 = L.LayerNormalization()\n",
    "    \n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[: tf.newaxis, :]\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm2(proj_input + proj_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_confog()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim\n",
    "        })\n",
    "        return config    \n",
    "    \n",
    "class TransformerDecoder(L.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = L.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = L.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            L.Dense(dense_dim, activation='relu'), L.Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm_1 = L.LayerNormalization()\n",
    "        self.layernorm_2 = L.LayerNormalization()\n",
    "        self.layernorm_3 = L.LayerNormalization()\n",
    "        self.support_masking = False\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=None\n",
    "        )\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1, value=encoder_outputs, key=encoder_outputs, attention_mask=None\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2\n",
    "        )\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59041ce3",
   "metadata": {
    "id": "59041ce3",
    "papermill": {
     "duration": 0.02078,
     "end_time": "2022-04-19T17:15:07.725525",
     "exception": false,
     "start_time": "2022-04-19T17:15:07.704745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Lets Define our model\n",
    "\n",
    "* Positional Embedding is applied to Encoder Inputs\n",
    "* Embedded Encoder Inputs are fed to the Transformer Encoder\n",
    "* Positional Embedding is applied to Decoder Inputs \n",
    "* Encoder Outputs and along with the Embedded Decoder Inputs are fed to the transformer Decoder\n",
    "* We optionally apply dropout to the outputs from the decoder block before feeding it to the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b27af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:15:07.769789Z",
     "iopub.status.busy": "2022-04-19T17:15:07.769002Z",
     "iopub.status.idle": "2022-04-19T17:15:11.474914Z",
     "shell.execute_reply": "2022-04-19T17:15:11.475446Z",
     "shell.execute_reply.started": "2022-04-19T16:41:42.112793Z"
    },
    "id": "6b6b27af",
    "outputId": "467a54ba-b7d2-48d9-cf7f-bcc5e6e639f2",
    "papermill": {
     "duration": 3.729544,
     "end_time": "2022-04-19T17:15:11.475593",
     "exception": false,
     "start_time": "2022-04-19T17:15:07.746049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape=(None, ), dtype=\"int64\", name=\"human\")\n",
    "x = PositionalEmbedding(config.X_LEN, config.NUM_ENCODER_TOKENS, config.EMBED_DIM)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(config.EMBED_DIM, config.DENSE_DIM, config.NUM_HEADS)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None, ), dtype=\"int64\", name=\"machine\" )\n",
    "x = PositionalEmbedding(config.Y_LEN, config.NUM_DECODER_TOKENS, config.EMBED_DIM)(decoder_inputs)\n",
    "x = TransformerDecoder(config.EMBED_DIM, config.DENSE_DIM, config.NUM_HEADS)(x, encoder_outputs)\n",
    "x = L.Dropout(0.5)(x)\n",
    "decoder_outputs = L.Dense(config.NUM_DECODER_TOKENS, activation=\"softmax\")(x)\n",
    "\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "transformer.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "transformer.summary()\n",
    "utils.plot_model(transformer, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664f4c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:15:11.530241Z",
     "iopub.status.busy": "2022-04-19T17:15:11.528519Z",
     "iopub.status.idle": "2022-04-19T17:15:11.530831Z",
     "shell.execute_reply": "2022-04-19T17:15:11.531287Z",
     "shell.execute_reply.started": "2022-04-19T16:41:46.074568Z"
    },
    "id": "8664f4c1",
    "papermill": {
     "duration": 0.0324,
     "end_time": "2022-04-19T17:15:11.531437",
     "exception": false,
     "start_time": "2022-04-19T17:15:11.499037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1, restore_best_weights=True, min_delta=1e-4)\n",
    "rlp = callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986826c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:15:11.589487Z",
     "iopub.status.busy": "2022-04-19T17:15:11.588613Z",
     "iopub.status.idle": "2022-04-19T17:19:29.560469Z",
     "shell.execute_reply": "2022-04-19T17:19:29.561005Z",
     "shell.execute_reply.started": "2022-04-19T16:41:46.082314Z"
    },
    "id": "986826c9",
    "outputId": "a431935d-8eb1-4d1d-fc4a-9588134bd9c8",
    "papermill": {
     "duration": 258.005138,
     "end_time": "2022-04-19T17:19:29.561211",
     "exception": false,
     "start_time": "2022-04-19T17:15:11.556073",
     "status": "completed"
    },
    "tags": [
     "same_step_2"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture training_log\n",
    "\n",
    "history = transformer.fit(\n",
    "    generate_batch(X_train, y_train), steps_per_epoch = np.ceil(len(X_train)/config.BATCH_SIZE),\n",
    "    validation_data=generate_batch(X_valid, y_valid), validation_steps=np.ceil(len(X_valid)/config.BATCH_SIZE),\n",
    "    epochs=config.MAX_EPOCHS, callbacks=[es, rlp], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc94d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:19:29.614789Z",
     "iopub.status.busy": "2022-04-19T17:19:29.613915Z",
     "iopub.status.idle": "2022-04-19T17:19:29.616847Z",
     "shell.execute_reply": "2022-04-19T17:19:29.617319Z",
     "shell.execute_reply.started": "2022-04-19T16:41:46.082314Z"
    },
    "id": "d8fc94d6",
    "papermill": {
     "duration": 0.03217,
     "end_time": "2022-04-19T17:19:29.617449",
     "exception": false,
     "start_time": "2022-04-19T17:19:29.585279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('training.log', 'w') as f: f.write(training_log.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a2d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:19:29.669598Z",
     "iopub.status.busy": "2022-04-19T17:19:29.668798Z",
     "iopub.status.idle": "2022-04-19T17:19:30.028795Z",
     "shell.execute_reply": "2022-04-19T17:19:30.029237Z",
     "shell.execute_reply.started": "2022-04-19T16:42:22.93183Z"
    },
    "id": "036a2d44",
    "outputId": "bfc25d5f-b98a-4251-fdd7-0d0261a5e062",
    "papermill": {
     "duration": 0.388763,
     "end_time": "2022-04-19T17:19:30.029386",
     "exception": false,
     "start_time": "2022-04-19T17:19:29.640623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "pd.DataFrame(history.history).plot(ax=ax)\n",
    "del history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546982b5",
   "metadata": {
    "id": "546982b5",
    "papermill": {
     "duration": 0.023925,
     "end_time": "2022-04-19T17:19:30.077703",
     "exception": false,
     "start_time": "2022-04-19T17:19:30.053778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8492d32",
   "metadata": {
    "id": "a8492d32",
    "papermill": {
     "duration": 0.023713,
     "end_time": "2022-04-19T17:19:30.125341",
     "exception": false,
     "start_time": "2022-04-19T17:19:30.101628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Lets see our model in action**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8eaa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:19:30.181573Z",
     "iopub.status.busy": "2022-04-19T17:19:30.180896Z",
     "iopub.status.idle": "2022-04-19T17:19:30.183571Z",
     "shell.execute_reply": "2022-04-19T17:19:30.183144Z",
     "shell.execute_reply.started": "2022-04-19T16:42:23.208867Z"
    },
    "id": "c2b8eaa5",
    "papermill": {
     "duration": 0.034088,
     "end_time": "2022-04-19T17:19:30.183677",
     "exception": false,
     "start_time": "2022-04-19T17:19:30.149589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this function converts the token ids to token text\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return \"\"\n",
    "\n",
    "# this function is used to generate predictions\n",
    "# target sequence is intialised as the start token\n",
    "# then predictions are taken from the model iteratively \n",
    "def predict_sequence(source):\n",
    "    target_seq = \"@\"\n",
    "    for i in range(14):\n",
    "        tok_target_seq = preprocess_input(target_seq, machine_tokenizer, config.Y_LEN).reshape(1, -1)\n",
    "        output_tokens = transformer.predict([source, tok_target_seq])\n",
    "        token_index = np.argmax(output_tokens[0, i, :])\n",
    "        token = word_for_id(token_index, machine_tokenizer)\n",
    "        target_seq += token\n",
    "        \n",
    "    return target_seq\n",
    "\n",
    "# this function decodes the complete sequence of token ids into text\n",
    "def decode_sequence(tokenizer, source):\n",
    "    target = list()\n",
    "    for i in source:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ''.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321eea53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:19:30.236734Z",
     "iopub.status.busy": "2022-04-19T17:19:30.235849Z",
     "iopub.status.idle": "2022-04-19T17:19:31.166237Z",
     "shell.execute_reply": "2022-04-19T17:19:31.167189Z",
     "shell.execute_reply.started": "2022-04-19T16:42:23.210716Z"
    },
    "id": "321eea53",
    "outputId": "a9d774bf-8f97-45c7-aa37-71218514def2",
    "papermill": {
     "duration": 0.95973,
     "end_time": "2022-04-19T17:19:31.167348",
     "exception": false,
     "start_time": "2022-04-19T17:19:30.207618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_text = 'saturday 19 september 1998'\n",
    "query = np.array(list(map(lambda x: preprocess_input(x, human_tokenizer, config.X_LEN), [query_text])))\n",
    "print('SOURCE     :', query_text)\n",
    "print('PREDICTION :', predict_sequence(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d15d13",
   "metadata": {
    "id": "e0d15d13",
    "papermill": {
     "duration": 0.024883,
     "end_time": "2022-04-19T17:19:31.216970",
     "exception": false,
     "start_time": "2022-04-19T17:19:31.192087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "name": "Attention-Is-All-You-Need.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 603.501486,
   "end_time": "2022-04-19T17:19:34.167951",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-19T17:09:30.666465",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
