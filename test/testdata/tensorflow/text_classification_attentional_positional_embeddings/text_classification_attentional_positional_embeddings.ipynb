{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7noRR_tsvQj6",
   "metadata": {
    "id": "7noRR_tsvQj6"
   },
   "source": [
    "<a href=\"https://www.kaggle.com/code/ritvik1909/text-classification-attention\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6727ba",
   "metadata": {
    "id": "cd6727ba",
    "papermill": {
     "duration": 0.012957,
     "end_time": "2022-03-31T16:24:21.587262",
     "exception": false,
     "start_time": "2022-03-31T16:24:21.574305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Classification Using Attention and Positional Embeddings\n",
    "\n",
    "Recently most of the natural language processing tasks are being dominated by the `Transformer` architecture. Transformers were introduced in the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762), which used a simple mechanism called `Neural Attention` as one of its building blocks. As the title suggests this architecture didn't require any recurrent layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6594f99",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-31T16:24:21.624487Z",
     "iopub.status.busy": "2022-03-31T16:24:21.623707Z",
     "iopub.status.idle": "2022-03-31T16:24:27.094642Z",
     "shell.execute_reply": "2022-03-31T16:24:27.094004Z",
     "shell.execute_reply.started": "2021-12-19T16:07:29.870867Z"
    },
    "executionInfo": {
     "elapsed": 3328,
     "status": "ok",
     "timestamp": 1648876773404,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "a6594f99",
    "papermill": {
     "duration": 5.494136,
     "end_time": "2022-03-31T16:24:27.094795",
     "exception": false,
     "start_time": "2022-03-31T16:24:21.600659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a57962",
   "metadata": {
    "id": "48a57962",
    "papermill": {
     "duration": 0.011937,
     "end_time": "2022-03-31T16:24:27.118566",
     "exception": false,
     "start_time": "2022-03-31T16:24:27.106629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will be using 20 news groups data in our notebooks which comes as a standard dataset in the `scikit-learn` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c1fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T16:24:27.147111Z",
     "iopub.status.busy": "2022-03-31T16:24:27.146301Z",
     "iopub.status.idle": "2022-03-31T16:24:40.349996Z",
     "shell.execute_reply": "2022-03-31T16:24:40.350508Z",
     "shell.execute_reply.started": "2021-12-19T16:07:35.49611Z"
    },
    "executionInfo": {
     "elapsed": 18718,
     "status": "ok",
     "timestamp": 1648876792116,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "511c1fd2",
    "papermill": {
     "duration": 13.220649,
     "end_time": "2022-03-31T16:24:40.350682",
     "exception": false,
     "start_time": "2022-03-31T16:24:27.130033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset='all')\n",
    "\n",
    "X = pd.Series(dataset['data'])\n",
    "y = pd.Series(dataset['target'])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, stratify=y, random_state=19)\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_valid = pd.get_dummies(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0fa502",
   "metadata": {
    "id": "fb0fa502",
    "papermill": {
     "duration": 0.011286,
     "end_time": "2022-03-31T16:24:40.374005",
     "exception": false,
     "start_time": "2022-03-31T16:24:40.362719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The concept of `Neural Attention` is fairly simple ie not all input information seen by a model is equally important to the task at hand. Although this concept has been utilised at vaious different places as well eg Max Pooling in CNNs, but the kind of attention we are looking for should be `context aware`.\n",
    "\n",
    "The attention mechanism allows output to focus attention on input while producing output while the self-attention model allows inputs to interact with each other i.e calculate attention of all other inputs with respect tt one input.\n",
    "\n",
    "In the paper, the authors proposed another type of attention mechanism called multi-headed attention which refers to the fact that the outer space of the self attention layer gets factored into a set of independent sub-spaces leanred separately, where each subspace is called a \"head\"\n",
    "\n",
    "There is a learnable dense projection present after the multihead attention which enables the layr to actually learn something, as opposed to being a purely stateless transformation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc578b76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T16:24:40.405951Z",
     "iopub.status.busy": "2022-03-31T16:24:40.399870Z",
     "iopub.status.idle": "2022-03-31T16:24:40.407809Z",
     "shell.execute_reply": "2022-03-31T16:24:40.408219Z",
     "shell.execute_reply.started": "2021-12-19T16:07:46.149062Z"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1648876792117,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "cc578b76",
    "papermill": {
     "duration": 0.022865,
     "end_time": "2022-03-31T16:24:40.408467",
     "exception": false,
     "start_time": "2022-03-31T16:24:40.385602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(L.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = L.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([L.Dense(dense_dim, activation='relu'), L.Dense(embed_dim)])\n",
    "        self.layernorm1 = L.LayerNormalization()\n",
    "        self.layernorm2 = L.LayerNormalization()\n",
    "    \n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[: tf.newaxis, :]\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm2(proj_input + proj_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_confog()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb0ce3",
   "metadata": {
    "id": "e1cb0ce3",
    "papermill": {
     "duration": 0.011173,
     "end_time": "2022-03-31T16:24:40.431117",
     "exception": false,
     "start_time": "2022-03-31T16:24:40.419944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The idea behind Positional Encoding is fairly simple as well, ie to give the model access to token order information, therefore we are going to add the token's position in the sentence to each word embedding\n",
    "\n",
    "Thus, one input word embedding will have to components: the usual token vector representing the token independent of any specific context, and a position vector representing the position of the token in the current sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db9b3dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T16:24:40.461368Z",
     "iopub.status.busy": "2022-03-31T16:24:40.460599Z",
     "iopub.status.idle": "2022-03-31T16:24:40.462951Z",
     "shell.execute_reply": "2022-03-31T16:24:40.462566Z",
     "shell.execute_reply.started": "2021-12-19T16:07:46.137032Z"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1648876792118,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "2db9b3dd",
    "papermill": {
     "duration": 0.020698,
     "end_time": "2022-03-31T16:24:40.463070",
     "exception": false,
     "start_time": "2022-03-31T16:24:40.442372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(L.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = L.Embedding(input_dim, output_dim)\n",
    "        self.position_embeddings = L.Embedding(sequence_length, output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afde9c93",
   "metadata": {
    "id": "afde9c93",
    "papermill": {
     "duration": 0.011052,
     "end_time": "2022-03-31T16:24:40.485320",
     "exception": false,
     "start_time": "2022-03-31T16:24:40.474268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we define some contants to parameterize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280fe4c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T16:24:40.510644Z",
     "iopub.status.busy": "2022-03-31T16:24:40.509859Z",
     "iopub.status.idle": "2022-03-31T16:24:40.513940Z",
     "shell.execute_reply": "2022-03-31T16:24:40.513540Z",
     "shell.execute_reply.started": "2021-12-19T16:07:46.179928Z"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1648876792119,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "280fe4c7",
    "papermill": {
     "duration": 0.017492,
     "end_time": "2022-03-31T16:24:40.514057",
     "exception": false,
     "start_time": "2022-03-31T16:24:40.496565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = 10_000\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "seq_length = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb3a8d",
   "metadata": {
    "id": "9ecb3a8d",
    "papermill": {
     "duration": 0.011166,
     "end_time": "2022-03-31T16:24:40.536738",
     "exception": false,
     "start_time": "2022-03-31T16:24:40.525572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The input texts are here tokenized and padded to a uniform sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d66cfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T16:24:40.571810Z",
     "iopub.status.busy": "2022-03-31T16:24:40.566381Z",
     "iopub.status.idle": "2022-03-31T16:24:49.253838Z",
     "shell.execute_reply": "2022-03-31T16:24:49.254595Z",
     "shell.execute_reply.started": "2021-12-19T16:07:46.189685Z"
    },
    "executionInfo": {
     "elapsed": 14924,
     "status": "ok",
     "timestamp": 1648876807019,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "17d66cfc",
    "papermill": {
     "duration": 8.706763,
     "end_time": "2022-03-31T16:24:49.254778",
     "exception": false,
     "start_time": "2022-03-31T16:24:40.548015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<unw>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=seq_length)\n",
    "X_valid = tokenizer.texts_to_sequences(X_valid)\n",
    "X_valid = sequence.pad_sequences(X_valid, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f65487a",
   "metadata": {
    "id": "6f65487a",
    "papermill": {
     "duration": 0.01132,
     "end_time": "2022-03-31T16:24:49.277897",
     "exception": false,
     "start_time": "2022-03-31T16:24:49.266577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Defining the model**\n",
    "The model architecture is fairly simple ie,:\n",
    "* Input Layer\n",
    "* Positional Embeddings\n",
    "* Transformer Block\n",
    "* Pooling\n",
    "* Dropout\n",
    "* Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d4968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T16:24:49.307177Z",
     "iopub.status.busy": "2022-03-31T16:24:49.306557Z",
     "iopub.status.idle": "2022-03-31T16:24:52.014778Z",
     "shell.execute_reply": "2022-03-31T16:24:52.015656Z",
     "shell.execute_reply.started": "2021-12-19T16:07:54.105332Z"
    },
    "executionInfo": {
     "elapsed": 3450,
     "status": "ok",
     "timestamp": 1648876810463,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "141d4968",
    "papermill": {
     "duration": 2.726304,
     "end_time": "2022-03-31T16:24:52.015828",
     "exception": false,
     "start_time": "2022-03-31T16:24:49.289524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(None, ), dtype=\"int64\")\n",
    "x = PositionalEmbedding(seq_length, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerBlock(embed_dim, dense_dim, num_heads)(x)\n",
    "x = L.GlobalMaxPooling1D()(x)\n",
    "x = L.Dropout(0.5)(x)\n",
    "outputs = L.Dense(20, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c00f20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T16:24:52.047519Z",
     "iopub.status.busy": "2022-03-31T16:24:52.046116Z",
     "iopub.status.idle": "2022-03-31T16:24:52.050660Z",
     "shell.execute_reply": "2022-03-31T16:24:52.051090Z",
     "shell.execute_reply.started": "2021-12-19T16:07:57.059649Z"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1648876810464,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "d1c00f20",
    "outputId": "bd62e4b1-9855-417c-ba4c-3421498659be",
    "papermill": {
     "duration": 0.022404,
     "end_time": "2022-03-31T16:24:52.051216",
     "exception": false,
     "start_time": "2022-03-31T16:24:52.028812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220efe0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T16:24:52.079868Z",
     "iopub.status.busy": "2022-03-31T16:24:52.079195Z",
     "iopub.status.idle": "2022-03-31T16:24:52.081785Z",
     "shell.execute_reply": "2022-03-31T16:24:52.081377Z",
     "shell.execute_reply.started": "2021-12-19T16:07:57.071427Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1648876810465,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "220efe0c",
    "papermill": {
     "duration": 0.018413,
     "end_time": "2022-03-31T16:24:52.081887",
     "exception": false,
     "start_time": "2022-03-31T16:24:52.063474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(verbose=1, patience=5, restore_best_weights=True)\n",
    "rlp = keras.callbacks.ReduceLROnPlateau(patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d14d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T16:24:52.108981Z",
     "iopub.status.busy": "2022-03-31T16:24:52.108220Z",
     "iopub.status.idle": "2022-03-31T16:26:11.847579Z",
     "shell.execute_reply": "2022-03-31T16:26:11.846932Z",
     "shell.execute_reply.started": "2021-12-19T16:07:57.083924Z"
    },
    "executionInfo": {
     "elapsed": 227250,
     "status": "ok",
     "timestamp": 1648877037706,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "1c8d14d0",
    "outputId": "89557c96-d6e9-46b1-acb3-f62258084fe2",
    "papermill": {
     "duration": 79.753721,
     "end_time": "2022-03-31T16:26:11.847749",
     "exception": false,
     "start_time": "2022-03-31T16:24:52.094028",
     "status": "completed"
    },
    "tags": [
     "same_step_1"
    ]
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "    callbacks=[es, rlp], epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdf465",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T16:26:12.630165Z",
     "iopub.status.busy": "2022-03-31T16:26:12.629441Z",
     "iopub.status.idle": "2022-03-31T16:26:15.973619Z",
     "shell.execute_reply": "2022-03-31T16:26:15.974083Z",
     "shell.execute_reply.started": "2021-12-19T16:09:17.294329Z"
    },
    "executionInfo": {
     "elapsed": 1267,
     "status": "ok",
     "timestamp": 1648877038958,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "20fdf465",
    "outputId": "83f8ec40-9ce5-455e-d0c4-132492c2e930",
    "papermill": {
     "duration": 3.759336,
     "end_time": "2022-03-31T16:26:15.974233",
     "exception": false,
     "start_time": "2022-03-31T16:26:12.214897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "history = pd.DataFrame(history.history)\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 12))\n",
    "fig.suptitle('Learning Curve', fontsize=24)\n",
    "history[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "history[['accuracy', 'val_accuracy']].plot(ax=ax[1])\n",
    "ax[0].set_title('Loss', fontsize=18)\n",
    "ax[1].set_title('Accuarcy', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ad997",
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1648877038963,
     "user": {
      "displayName": "Ritvik Rastogi",
      "userId": "01504835329516909297"
     },
     "user_tz": -330
    },
    "id": "0b5ad997",
    "papermill": {
     "duration": 0.370269,
     "end_time": "2022-03-31T16:26:16.713170",
     "exception": false,
     "start_time": "2022-03-31T16:26:16.342901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "Text-Classification-Attention-Positional Embeddings.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/Ritvik19/Implemented-Data-Science/blob/main/Text-Classification-Attention-Positional%20Embeddings.ipynb",
     "timestamp": 1648876686676
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 126.733939,
   "end_time": "2022-03-31T16:26:20.094746",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-31T16:24:13.360807",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
